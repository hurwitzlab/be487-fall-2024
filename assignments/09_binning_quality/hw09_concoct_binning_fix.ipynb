{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de7bac8",
   "metadata": {},
   "source": [
    "# Metagenomic Binning\n",
    "\n",
    "This notebook will go through the workflow for binning contigs into species-level bins from a metagenome assembled genome (MAG).\n",
    "\n",
    "1. Create species-level bins for your megahit MAGs\n",
    "2. Create species-level bins for your metaspades MAGs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ebed36",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "You will need to rerun this section each time you come back to this notebook to reset all directories and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a46521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the variables for your netid and xfile\n",
    "netid = \"YOUR_NETID\"\n",
    "xfile = \"YOUR_XFILE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d388ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go into the working directory\n",
    "work_dir = \"/xdisk/bhurwitz/bh_class/\" + netid + \"/assignments/09_metag_binning\"\n",
    "%cd $work_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380dffed",
   "metadata": {},
   "source": [
    "## Creating a config file\n",
    "The scripts below executes code that requires certain variables to be set. So we don't need to edit the code in the script, we are going to use a config file that defines all of these variables for us. Then when we want to use these variables in the script, we will \"source\" the config file to set the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049cf341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a config file with all of the variables you need\n",
    "# notice that we are using the reads post-trimming, and post-human removal\n",
    "!echo \"export NETID=$netid\" > config.sh\n",
    "!echo \"export XFILE=$xfile\" >> config.sh\n",
    "!echo \"export WORK_DIR=/xdisk/bhurwitz/bh_class/$netid/assignments/09_metag_binning\" >> config.sh\n",
    "!echo \"export XFILE_DIR=/xdisk/bhurwitz/bh_class/$netid/assignments/05_getting_data\" >> config.sh\n",
    "!echo \"export FASTQ_DIR=/xdisk/bhurwitz/bh_class/$netid/assignments/07_contam_removal\" >> config.sh\n",
    "!echo \"export MEGAHIT_DIR=/xdisk/bhurwitz/bh_class/$netid/assignments/08_assembly/out_megahit\" >> config.sh\n",
    "!echo \"export METASPADES_DIR=/xdisk/bhurwitz/bh_class/$netid/assignments/08_assembly/out_spades\" >> config.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1996dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the config file to be sure it is correct\n",
    "# Is your netid and xfile correct? Do you have the right directories?\n",
    "!cat config.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeaabfe",
   "metadata": {},
   "source": [
    "## Step 1: Aligning reads to your megahit contigs via bwa, and binning with concoct \n",
    "\n",
    "In this step, we will align the reads from your \"screened and cleaned\" fastq file back to the contigs you created using each of the assemblers: metaspades and megahit. In the next step, we will use this information to determine the \"coverage\" for each of the contigs. These data will be used by the binning step to place contigs into the same species-level (hopefully single organism) bins based on the coverage and sequence composition of the contigs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7e3021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a script to align your reads to each of your assemblies, and then bin\n",
    "# A few important points:\n",
    "# 1. We are using the variables from the config file via the `source ./config.sh` command in the script.\n",
    "# 2. bwa aligns each of the fastq files in the trimmed and human filtered $FASTQ_DIR\n",
    "# 3. We then run concoct to bin the contigs\n",
    "# The results will be written into our $WORK_DIR\n",
    "my_code = '''#!/bin/bash\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --nodes=1             \n",
    "#SBATCH --time=10:00:00   \n",
    "#SBATCH --partition=standard\n",
    "#SBATCH --account=bh_class\n",
    "#SBATCH --array=0-4                         \n",
    "#SBATCH --output=Job-mega-bins-%a.out\n",
    "#SBATCH --cpus-per-task=24\n",
    "#SBATCH --mem=8G                                  \n",
    "\n",
    "pwd; hostname; date\n",
    "\n",
    "source ./config.sh\n",
    "names=($(cat $XFILE_DIR/$XFILE))\n",
    "\n",
    "SAMPLE_ID=${names[${SLURM_ARRAY_TASK_ID}]}\n",
    "\n",
    "### reads after trimming and human filtering\n",
    "PAIR1=${FASTQ_DIR}/${SAMPLE_ID}_1.fastq.gz\n",
    "PAIR2=${FASTQ_DIR}/${SAMPLE_ID}_2.fastq.gz\n",
    "\n",
    "MEGAHIT_OUTDIR=${WORK_DIR}/out_megahit\n",
    "OUTDIR=${MEGAHIT_OUTDIR}/${SAMPLE_ID}\n",
    "\n",
    "### create the outdir if it does not exist\n",
    "if [[ ! -d \"$MEGAHIT_OUTDIR\" ]]; then\n",
    "  echo \"$MEGAHIT_OUTDIR does not exist. Directory created\"\n",
    "  mkdir $MEGAHIT_OUTDIR\n",
    "fi\n",
    "\n",
    "if [[ ! -d \"$OUTDIR\" ]]; then\n",
    "  echo \"$OUTDIR does not exist. Directory created\"\n",
    "  mkdir $OUTDIR\n",
    "fi\n",
    "\n",
    "### final contigs\n",
    "CONTIGS=\"${MEGAHIT_DIR}/${SAMPLE_ID}/final.contigs.fa\"\n",
    "\n",
    "### create the index from the contigs\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/bwa:0.7.8--he4a0461_9.sif bwa index ${CONTIGS}\n",
    "\n",
    "### align reads to the index\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/bwa:0.7.8--he4a0461_9.sif bwa mem \\\n",
    "-t $SLURM_CPUS_PER_TASK \\\n",
    "${CONTIGS} \\\n",
    "${PAIR1} \\\n",
    "${PAIR2} \\\n",
    "> $OUTDIR/result.sam\n",
    "\n",
    "### convert sam to bam\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/samtools:1.17--hd87286a_1.sif samtools view \\\n",
    "-b -F 4 ${OUTDIR}/result.sam > ${OUTDIR}/result.bam\n",
    "\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/samtools:1.17--hd87286a_1.sif samtools \\\n",
    "sort ${OUTDIR}/result.bam > ${OUTDIR}/my_sorted.bam\n",
    "\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/samtools:1.17--hd87286a_1.sif samtools \\\n",
    "index ${OUTDIR}/my_sorted.bam\n",
    "\n",
    "### run the binning step\n",
    "### following the protocol here: https://concoct.readthedocs.io/en/latest/usage.html\n",
    "echo \"Starting cut_up_fasta.py\"\n",
    "MIN_CONTIG_LENGTH=10000\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/concoct:1.1.0--py311h245ed52_4.sif cut_up_fasta.py \\\n",
    "${CONTIGS} \\\n",
    "--chunk_size ${MIN_CONTIG_LENGTH} \\\n",
    "--overlap_size 0 \\\n",
    "--bedfile ${OUTDIR}/contigs_10k.bed \\\n",
    "--merge_last \\\n",
    "> ${OUTDIR}/contigs_10k.fa\n",
    "\n",
    "echo \"Starting concoct_coverage_table.py\"\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/concoct:1.1.0--py311h245ed52_4.sif concoct_coverage_table.py \\\n",
    "${OUTDIR}/contigs_10k.bed ${OUTDIR}/my_sorted.bam > ${OUTDIR}/coverage_table.tsv\n",
    "\n",
    "echo \"Starting concoct\"\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/concoct:1.1.0--py311h245ed52_4.sif concoct --threads 24 \\\n",
    "--composition_file ${OUTDIR}/contigs_10k.fa --coverage_file ${OUTDIR}/coverage_table.tsv -b ${OUTDIR}/out_concoct/\n",
    "\n",
    "echo \"Starting merge_cutup_clustering.py\"\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/concoct:1.1.0--py311h245ed52_4.sif \\\n",
    "merge_cutup_clustering.py ${OUTDIR}/out_concoct/clustering_gt1000.csv > ${OUTDIR}/out_concoct/clustering_merged.csv\n",
    "\n",
    "echo \"Starting extract_fasta_bins.py\"\n",
    "mkdir ${OUTDIR}/out_concoct/fasta_bins\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/concoct:1.1.0--py311h245ed52_4.sif \\\n",
    "extract_fasta_bins.py ${CONTIGS} ${OUTDIR}/out_concoct/clustering_merged.csv --output_path ${OUTDIR}/out_concoct/fasta_bins\n",
    "\n",
    "'''\n",
    "\n",
    "with open('megahit_bin_parallel.sh', mode='w') as file:\n",
    "    file.write(my_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b9374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the code and make sure your script above was created.\n",
    "!cat megahit_bin_parallel.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e42306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you should be in your working directory when you run this script\n",
    "# do you see your config.sh file, and the megahit_bin_parallel.sh script?\n",
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe884278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run sbatch to run the megahit contig binning\n",
    "# Remember that this may take a while to run, so take a break, and get a coffee.\n",
    "!sbatch ./megahit_bin_parallel.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3699608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check if it is running using the squeue command\n",
    "# Check for all jobs under your netid\n",
    "!squeue --user=$netid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e70ffc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Once your jobs have run (or are running) you can check the progress\n",
    "# and also look for errors in the *out files\n",
    "# Note that this step will take 1-2 hours per file\n",
    "# For example, you can look at Job-mega-bins-0.out\n",
    "!cat Job-mega-bins-0.out | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa8c919",
   "metadata": {},
   "source": [
    "Rock on! You have created bins for your megahit contigs. These bins should represent the species (and individual organisms) present in your samples.\n",
    "\n",
    "This step will generate a series of files for each of your samples. Take a look at the files generated. In particular you should see a series of *.fasta files preceeded by numbers. These are the different genome bins predicted by binning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d7e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check that you have bins for your contigs from megahit.\n",
    "# These bins are in files named like this: \"1.fa\"\n",
    "!ls $work_dir/out_megahit/ERR*/out_concoct/fasta_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54056fa1",
   "metadata": {},
   "source": [
    "That is correct! You can see that each one of the files 1.fa, 2.fa, 3.fa... represents one bin, and that bin should contain one species, and hopefully one organism, and we can see how complete that bin is (meaning the % of the genome of that species that is represented). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99c2751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check one, for example mine is called ERR2198611/1.fa\n",
    "# and there are 6 contigs in that file. How about yours?\n",
    "!egrep '>' $work_dir/out_megahit/YOUR_SAMPLE/out_concoct/fasta_bins/1.fa | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa97c272",
   "metadata": {},
   "source": [
    "Now, we are going to generate a concatenated file that contains all of our genome bins put together. We will change the fasta header name to include the bin number so that we can tell them apart later.\n",
    "\n",
    "Let's write a script to do this. Note that this script will just run locally on this machine, so no coffee break required!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec3c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_code = '''#!/bin/bash\n",
    "\n",
    "source ./config.sh\n",
    "names=($(cat $XFILE_DIR/$XFILE))\n",
    "\n",
    "MEGAHIT_OUTDIR=${WORK_DIR}/out_megahit\n",
    "\n",
    "cd $MEGAHIT_OUTDIR\n",
    "\n",
    "for i in {0..4}; do\n",
    "    SAMPLE_ID=${names[$i]}\n",
    "    BIN_DIR=${MEGAHIT_OUTDIR}/${SAMPLE_ID}/out_concoct/fasta_bins\n",
    "    echo ${SAMPLE_ID}\n",
    "    touch ${SAMPLE_ID}.all_contigs.fna\n",
    "    cd ${BIN_DIR} \n",
    "    for file in *.fa; do\n",
    "        num=$(echo $file | sed 's/.fa//')\n",
    "        cat $num.fa | sed -e \"s/^>/>${num}_/\" >> $MEGAHIT_OUTDIR/${SAMPLE_ID}.all_contigs.fna\n",
    "    done\n",
    "    cd $MEGAHIT_OUTDIR\n",
    "done\n",
    "\n",
    "cd $WORK_DIR\n",
    "\n",
    "'''\n",
    "\n",
    "with open('megahit_add_bin_nums.sh', mode='w') as file:\n",
    "    file.write(my_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c70637",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x ./megahit_add_bin_nums.sh\n",
    "!ls -l megahit_add_bin_nums.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e89aa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./megahit_add_bin_nums.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1768ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check to see if the re-naming worked, where all ids are \n",
    "# named according to their bin id \"_\" name.\n",
    "# My concatenated bin file is called ERR2198611.all_contigs.fna\n",
    "# Change this to one of your samples\n",
    "# You should see the the ids all start with their bin_id now\n",
    "!egrep '>' $work_dir/out_megahit/ERR2198611.all_contigs.fna | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09bb449",
   "metadata": {},
   "source": [
    "Looks great! Now we have all of our bins assigned, and we have all of our contigs in a single file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c855032b",
   "metadata": {},
   "source": [
    "## Step 2: Binning contigs from your Metaspades Assembly\n",
    "\n",
    "Rinse and repeat!\n",
    "\n",
    "In this step, we will create species-level bins for the contigs that were created from your metaspades assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a script to align your reads to each of your assemblies, and then bin\n",
    "# A few important points:\n",
    "# 1. We are using the variables from the config file via the `source ./config.sh` command in the script.\n",
    "# 2. bwa aligns each of the fastq files in the trimmed and human filtered $FASTQ_DIR\n",
    "# 3. concoct is used to bin the contigs into \"species-level\" bins \n",
    "# The results will be written into our $WORK_DIR\n",
    "my_code = '''#!/bin/bash\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --nodes=1             \n",
    "#SBATCH --time=10:00:00   \n",
    "#SBATCH --partition=standard\n",
    "#SBATCH --account=bh_class\n",
    "#SBATCH --array=0-4                         \n",
    "#SBATCH --output=Job-spades-bins-%a.out\n",
    "#SBATCH --cpus-per-task=24\n",
    "#SBATCH --mem=8G                                  \n",
    "\n",
    "pwd; hostname; date\n",
    "\n",
    "source ./config.sh\n",
    "names=($(cat $XFILE_DIR/$XFILE))\n",
    "\n",
    "SAMPLE_ID=${names[${SLURM_ARRAY_TASK_ID}]}\n",
    "\n",
    "### reads after trimming and human filtering\n",
    "PAIR1=${FASTQ_DIR}/${SAMPLE_ID}_1.fastq.gz\n",
    "PAIR2=${FASTQ_DIR}/${SAMPLE_ID}_2.fastq.gz\n",
    "\n",
    "METASPADES_OUTDIR=${WORK_DIR}/out_spades\n",
    "OUTDIR=${METASPADES_OUTDIR}/${SAMPLE_ID}\n",
    "\n",
    "### create the outdir if it does not exist\n",
    "if [[ ! -d \"$METASPADES_OUTDIR\" ]]; then\n",
    "  echo \"$METASPADES_OUTDIR does not exist. Directory created\"\n",
    "  mkdir $METASPADES_OUTDIR\n",
    "fi\n",
    "\n",
    "if [[ ! -d \"$OUTDIR\" ]]; then\n",
    "  echo \"$OUTDIR does not exist. Directory created\"\n",
    "  mkdir $OUTDIR\n",
    "fi\n",
    "\n",
    "### final contigs\n",
    "CONTIGS=\"${METASPADES_DIR}/${SAMPLE_ID}/contigs.fasta\"\n",
    "\n",
    "### create the index from the contigs\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/bwa:0.7.8--he4a0461_9.sif bwa index ${CONTIGS}\n",
    "\n",
    "### align reads to the index\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/bwa:0.7.8--he4a0461_9.sif bwa mem \\\n",
    "-t $SLURM_CPUS_PER_TASK \\\n",
    "${CONTIGS} \\\n",
    "${PAIR1} \\\n",
    "${PAIR2} \\\n",
    "> $OUTDIR/result.sam\n",
    "\n",
    "### convert sam to bam\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/samtools:1.17--hd87286a_1.sif samtools view \\\n",
    "-b -F 4 ${OUTDIR}/result.sam > ${OUTDIR}/result.bam\n",
    "\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/samtools:1.17--hd87286a_1.sif samtools \\\n",
    "sort ${OUTDIR}/result.bam > ${OUTDIR}/my_sorted.bam\n",
    "\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/samtools:1.17--hd87286a_1.sif samtools \\\n",
    "index ${OUTDIR}/my_sorted.bam\n",
    "\n",
    "### run the binning step\n",
    "### following the protocol here: https://concoct.readthedocs.io/en/latest/usage.html\n",
    "echo \"Starting cut_up_fasta.py\"\n",
    "MIN_CONTIG_LENGTH=10000\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/concoct:1.1.0--py311h245ed52_4.sif cut_up_fasta.py \\\n",
    "${CONTIGS} \\\n",
    "--chunk_size ${MIN_CONTIG_LENGTH} \\\n",
    "--overlap_size 0 \\\n",
    "--bedfile ${OUTDIR}/contigs_10k.bed \\\n",
    "--merge_last \\\n",
    "> ${OUTDIR}/contigs_10k.fa\n",
    "\n",
    "echo \"Starting concoct_coverage_table.py\"\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/concoct:1.1.0--py311h245ed52_4.sif concoct_coverage_table.py \\\n",
    "${OUTDIR}/contigs_10k.bed ${OUTDIR}/my_sorted.bam > ${OUTDIR}/coverage_table.tsv\n",
    "\n",
    "echo \"Starting concoct\"\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/concoct:1.1.0--py311h245ed52_4.sif concoct --threads 24 \\\n",
    "--composition_file ${OUTDIR}/contigs_10k.fa --coverage_file ${OUTDIR}/coverage_table.tsv -b ${OUTDIR}/out_concoct/\n",
    "\n",
    "echo \"Starting merge_cutup_clustering.py\"\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/concoct:1.1.0--py311h245ed52_4.sif \\\n",
    "merge_cutup_clustering.py ${OUTDIR}/out_concoct/clustering_gt1000.csv > ${OUTDIR}/out_concoct/clustering_merged.csv\n",
    "\n",
    "echo \"Starting extract_fasta_bins.py\"\n",
    "mkdir ${OUTDIR}/out_concoct/fasta_bins\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/concoct:1.1.0--py311h245ed52_4.sif \\\n",
    "extract_fasta_bins.py ${CONTIGS} ${OUTDIR}/out_concoct/clustering_merged.csv --output_path ${OUTDIR}/out_concoct/fasta_bins\n",
    "\n",
    "'''\n",
    "\n",
    "with open('metaspades_bin_parallel.sh', mode='w') as file:\n",
    "    file.write(my_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a30aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the code was created\n",
    "!cat metaspades_bin_parallel.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2049c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you should be in your working directory when you run this script\n",
    "# do you see your config.sh file, and the metaspades_bin_parallel.sh script?\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302db4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run the sbatch script, this should take ~1 hour to run\n",
    "# Time for some coffee..\n",
    "!sbatch ./metaspades_bin_parallel.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welcome back, let's see if the job is still running\n",
    "!squeue --user=bhurwitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed5ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check that you have bins for your contigs from megahit.\n",
    "# These bins are in files named like this: \"ERR2198611.001.fasta\"\n",
    "!ls $work_dir/out_spades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c45a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_code = '''#!/bin/bash\n",
    "\n",
    "source ./config.sh\n",
    "names=($(cat $XFILE_DIR/$XFILE))\n",
    "\n",
    "METASPADES_OUTDIR=${WORK_DIR}/out_spades\n",
    "\n",
    "cd $METASPADES_OUTDIR\n",
    "\n",
    "for i in {0..4}; do\n",
    "    SAMPLE_ID=${names[$i]}\n",
    "    BIN_DIR=${METASPADES_OUTDIR}/${SAMPLE_ID}/out_concoct/fasta_bins\n",
    "    echo ${SAMPLE_ID}\n",
    "    touch ${SAMPLE_ID}.all_contigs.fna\n",
    "    cd ${BIN_DIR} \n",
    "    for file in *.fa; do\n",
    "        num=$(echo $file | sed 's/.fa//')\n",
    "        cat $num.fa | sed -e \"s/^>/>${num}_/\" >> $METASPADES_OUTDIR/${SAMPLE_ID}.all_contigs.fna\n",
    "    done\n",
    "    cd $METASPADES_OUTDIR\n",
    "done\n",
    "\n",
    "cd $WORK_DIR\n",
    "\n",
    "'''\n",
    "\n",
    "with open('metaspades_add_bin_nums.sh', mode='w') as file:\n",
    "    file.write(my_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9155d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change permissions and check to see you have the script\n",
    "!chmod +x ./metaspades_add_bin_nums.sh\n",
    "!ls -l metaspades_add_bin_nums.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc24bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the script to add bin ids and create a single fasta\n",
    "!./metaspades_add_bin_nums.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fb4fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check to see if the re-naming worked, where all ids are \n",
    "# named according to their bin id \"_\" name.\n",
    "# My concatenated bin file is called ERR2198611.fasta\n",
    "# Change this to one of your samples\n",
    "# You should see the the ids all start with their bin_id now\n",
    "!egrep '>' $work_dir/out_spades/YOUR_FILE.all_contigs.fna | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9446f2",
   "metadata": {},
   "source": [
    "You did it! We now have created bins for all of our contigs, and we have a single fasta file for each that we will now run through the \n",
    "Assembly quality control process. But, that is for next time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83501ab5",
   "metadata": {},
   "source": [
    "## Final Step\n",
    "Copy your notebook to the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b6190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp ~/09_concoct_binning.ipynb $work_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
