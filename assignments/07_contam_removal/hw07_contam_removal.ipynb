{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de7bac8",
   "metadata": {},
   "source": [
    "# Removing Human Contamination\n",
    "\n",
    "This notebook will go through the workflow for removing human contamination in a microbiome. \n",
    "\n",
    "-----------\n",
    "\n",
    "Sections:\n",
    "\n",
    "1. Remove all reads mapping to the human genome.\n",
    "\n",
    "-----------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ebed36",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Set the variables you need for running the analyses in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a46521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the variables for your netid and xfile\n",
    "netid = \"MY_NETID\"\n",
    "xfile = \"MY_XFILE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d388ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go into the working directory\n",
    "work_dir = \"/xdisk/bhurwitz/bh_class/\" + netid + \"/assignments/07_contam_removal\"\n",
    "%cd $work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec5fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the fastq directory. This is where we have our trimmed fastq files.\n",
    "fastq_dir = \"/xdisk/bhurwitz/bh_class/\" + netid + \"/assignments/06_qc_trimming/trimmed_reads\"\n",
    "xfile_dir = \"/xdisk/bhurwitz/bh_class/\" + netid + \"/assignments/05_getting_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380dffed",
   "metadata": {},
   "source": [
    "## Creating a config file\n",
    "The scripts below executes code that requires certain variables to be set. So we don't need to edit the code in the script, we are going to use a config file that defines all of these variables for us. Then when we want to use these variables in the script, we will \"source\" the config file to set the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049cf341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a config file with all of the variables you need\n",
    "!echo \"export NETID=$netid\" > config.sh\n",
    "!echo \"export XFILE=$xfile\" >> config.sh\n",
    "!echo \"export WORK_DIR=$work_dir\" >> config.sh\n",
    "!echo \"export FASTQ_DIR=$fastq_dir\" >> config.sh\n",
    "!echo \"export XFILE_DIR=$xfile_dir\" >> config.sh\n",
    "!echo \"export BOWTIE2=/contrib/singularity/shared/bhurwitz/bowtie2:2.5.1--py39h6fed5c7_2.sif\" >> config.sh\n",
    "!echo \"export HUM_DB=/groups/bhurwitz/databases/chm13.draft_v1.0_plusY/chm13.draft_v1.0_plusY\" >> config.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1996dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the config file to be sure it is correct\n",
    "# Is your netid and xfile correct? Do you have the right directories?\n",
    "!cat config.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeaabfe",
   "metadata": {},
   "source": [
    "## Step 1: Mapping reads to the human genome\n",
    "\n",
    "In this step, we will map all of our trimmed reads to the complete human genome using a tool called Bowtie2. \n",
    "\n",
    "It is important to note that this alignment process is imperfect, and many human reads can fail to align from a microbiome. When we look at the taxonomic composition of our samples with Kraken2 later in this class, we will assess how well we did by comparing to a database that contains viruses, microbes, and human (post-human removal).\n",
    "\n",
    "First, let's run bowtie to remove the majority of human reads. Let's write a run script to align all of our trimmed reads to the human genome and remove those that align."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7e3021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a script to run bowtie2 to align reads to a human reference\n",
    "# A few important points:\n",
    "# 1. We are using the variables from the config file via the `source ./config.sh`\n",
    "# 2. bowtie2 runs on each of the fastq files in the trimmed $FASTQ_DIR\n",
    "# 3. The results will be written into our $WORK_DIR\n",
    "# 4. Notice that we are asking for alot more resource (24 cores and 5G of memory per core)\n",
    "#    we are also asking for more time (24 hours)\n",
    "my_code = '''#!/bin/bash\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --nodes=1             \n",
    "#SBATCH --time=24:00:00   \n",
    "#SBATCH --partition=standard\n",
    "#SBATCH --account=bh_class\n",
    "#SBATCH --array=0-7                         \n",
    "#SBATCH --output=07A_remove_human-%a.out\n",
    "#SBATCH --cpus-per-task=24\n",
    "#SBATCH --mem-per-cpu=5G                                    \n",
    "\n",
    "pwd; hostname; date\n",
    "\n",
    "source $SLURM_SUBMIT_DIR/config.sh\n",
    "names=($(cat $XFILE_DIR/$XFILE))\n",
    "\n",
    "SAMPLE_ID=${names[${SLURM_ARRAY_TASK_ID}]}\n",
    "\n",
    "PAIR1=${FASTQ_DIR}/${SAMPLE_ID}_1.fastq.gz\n",
    "PAIR2=${FASTQ_DIR}/${SAMPLE_ID}_2.fastq.gz\n",
    "\n",
    "### reads with human removed\n",
    "BOWTIE_NAME=\"${WORK_DIR}/${SAMPLE_ID}_%.fastq.gz\"\n",
    "SAM_NAME=\"${WORK_DIR}/${SAMPLE_ID}_human_removed.sam\"\n",
    "\n",
    "### reads mapped to human\n",
    "MET_NAME=\"${WORK_DIR}/${SAMPLE_ID}_hostmap.log\"\n",
    "\n",
    "apptainer run ${BOWTIE2} bowtie2 \\\n",
    "    -p 24 -x $HUM_DB -1 $PAIR1 -2 $PAIR2 --un-conc-gz $BOWTIE_NAME 1> $SAM_NAME 2> $MET_NAME\n",
    "\n",
    "rm $SAM_NAME\n",
    "'''\n",
    "\n",
    "with open('07A_remove_human.sh', mode='w') as file:\n",
    "    file.write(my_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e42306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you should be in your working directory when you run this script\n",
    "# do you see your config.sh file, and the 07A_remove_human.sh script?\n",
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480dc38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the launcher script to kick off our pipeline.\n",
    "\n",
    "my_code = '''#! /bin/bash\n",
    "\n",
    "# 07A_remove_human: first job - no dependencies\n",
    "job1=$(sbatch 07A_remove_human.sh)\n",
    "jid1=$(echo $job1 | sed 's/^Submitted batch job //')\n",
    "echo $jid1\n",
    "\n",
    "'''\n",
    "\n",
    "with open('07_launch_pipeline.sh', mode='w') as file:\n",
    "    file.write(my_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9c59e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the pipeline script executable\n",
    "!chmod +x *.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e36574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's run it!\n",
    "!./07_launch_pipeline.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3699608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check if it is running using the squeue command\n",
    "# Check for all jobs under your netid\n",
    "!squeue --user=$netid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b30b51",
   "metadata": {},
   "source": [
    "### Time to wait...\n",
    "\n",
    "Great job! You kicked off a script to remove *most* of the human reads from your fastq files. We will double check this when we run kraken2 on the files to classify each of the reads by taxonomy. But, for now, we just need to wait a short time for the josnb to finish running. Come back to this assignment in a few hours to run the hw07_check.ipynb notebook.\n",
    "\n",
    "Before you go...another quick note, in the \"real-world\" you may need to remove additional contamination using the same approach. For example, the sequencing center may have use PhiX as a \"spike-in\" to assess the quality of the sequencing run with a known quantity of DNA. Or, you may have created a microbiome with a different \"host\". You can use the same approach as above to remove reads from any genome you think may be contaminating your sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83501ab5",
   "metadata": {},
   "source": [
    "## Final Step\n",
    "Copy your notebook to the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b6190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ~/be487-fall-2024/assignments/07_contam_removal/hw07_contam_removal.ipynb $work_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
