{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRA Toolkit\n",
    "\n",
    "### Questions:\n",
    "- How can I download FASTQ files from the SRA in an automated way?\n",
    "- What options are available for downloading sequence data via teh SRA toolkit?\n",
    "### Objectives:\n",
    "- Download sequence data for our example project.\n",
    "### Keypoints:\n",
    "- The sra-tool kit allows you to download FASTQ data \n",
    "- The `fasterq-dump` commands has multiple options for downloading sequence data\n",
    "- Typically, we use the `--split-spot` option for `fasterq-dump` to split the files in for R1/R2, forward and reverse reads \n",
    "\n",
    "## The Sequence Read Archive (SRA)\n",
    "In the last exercise, we learned that one of the biggest repositories for genomic/metagenomic data is the National Certer for \n",
    "Biotechnology Information (NCBI). However, accessing these data can be tricky, and requires knowledge about how the data are organized. Users need to jump from the `Bioproject` page, to the `Biosample` page, then to the `SRA experiments`. This is not trivial, and would take you a long time to download all of the data you need from a webpage. Plus, downloading the data to our laptop, and then uploding to the HPC is cumbersome. Instead, we can download the data directly to the HPC using a bioinformatics tool called sra-tools.\n",
    "\n",
    "Instead we can use the `SRA Toolkit`. Let's explore this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "netid = \"YOUR_NETID\"\n",
    "%cd /xdisk/bhurwitz/bh_class/$netid/exercises/05_getting_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "my_data = '''Accessions\n",
    "SRR10153499\n",
    "SRR10153504\n",
    "SRR10153506\n",
    "SRR10153508\n",
    "SRR10153510\n",
    "SRR10153512\n",
    "SRR10153514\n",
    "SRR10153573\n",
    "SRR10153500\n",
    "SRR10153501\n",
    "SRR10153502\n",
    "SRR10153503\n",
    "SRR10153505\n",
    "SRR10153507\n",
    "SRR10153509\n",
    "SRR10153511\n",
    "SRR10153513\n",
    "SRR10153515\n",
    "'''\n",
    "with open('SRA-accessions.txt', mode='w') as file:\n",
    "    file.write(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat SRA-accessions.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using fasterq-dump to download the data\n",
    "\n",
    "We will use `fasterq-dump` from the sra-tool kit to retrieve data from the SRA. Let's see \n",
    "some of the parameters that this tool can offer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!apptainer run /contrib/singularity/shared/bhurwitz/sra-tools-3.0.3.sif fasterq-dump --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! There are a lot of options. First, let's focus on the split options:\n",
    "\n",
    "```\n",
    "-s|--split-spot                  split spots into reads\n",
    "-S|--split-files                 write reads into different files\n",
    "-3|--split-3                     writes single reads into special file\n",
    "   --concatenate-reads           writes whole spots into one file\n",
    "```\n",
    "\n",
    "#### --split-spot (-s)\n",
    "\n",
    "This flag will generate a unique file which will contain all the information for the \n",
    "library, no matter if those reads are forward or reverse sequenced. Each \"spot\" is like a piece of DNA.\n",
    "Each read will come with the 4 lines in the usual in the `FASTQ` format.\n",
    "\n",
    "\n",
    "#### ---split-file (-S)\n",
    "\n",
    "With this statement, we will end with separate files for the forward and the reverse reads\n",
    "(1.fastq and 2.fastq respectively). Nevertheless, the unmated reads (those present in\n",
    "the forward but without their complement in reverse and vice versa) will also be located\n",
    "in their respective file. This can be useful for k-mer based analyses, but usually we\n",
    "will prefer to exclude the unmated reads when assembling genomes from metagenomes. This option\n",
    "will write each read with the four lines in the usual `FASTQ` format.\n",
    "\n",
    "#### --concatenate-reads\n",
    "\n",
    "The information for each read is concatenated and each new spot (information from the forward\n",
    "and reverse) is written alongside the four lines characteristic of the `FASTQ` format.\n",
    "\n",
    "#### --split-spot\n",
    "\n",
    "This is the default option for `fasterq-dump`. The source file is split in a file containing the \n",
    "forward reads (_i.e._ 1.fastq) and the reverse ones (_i.e._ 2.fastq). Unmated reads are placed in \n",
    "a 3.fastq or SRA-code-name file. Each read is written with the 4 characteristic lines of the `FASTQ` format.\n",
    "Most of the sequencing projects are now in paired-end read format. This is also the case for the reads that we\n",
    "will use, so this is the right option for our datasets.\n",
    "\n",
    "\n",
    "Typically we use --skip-technical so we don't bother downloading a third read file with the barcodes and primers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run one example with the first accession from our data field: SRR10153499. We will use the \n",
    "`--stdout` option, so our output is displayed in the terminal. Also, we will use some of the commands that we \n",
    "reviewed in the past lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!apptainer run /contrib/singularity/shared/bhurwitz/sra-tools-3.0.3.sif fasterq-dump -s --stdout SRR10153499 --skip-technical | head -n 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see something like this:\n",
    "\n",
    "```\n",
    "@SRR10153499.1 1 length=250\n",
    "TACGGAGGATACGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGCAGGTGGTCCTGCAAGTCAGTGGTGAAAAGCTGAGGCTCAACCTCAGCCTTGCCGTTGAAACTGCAAGACTTGAGAGTACATGATGTGGGCGGAATGCGTAGTGTAGCGGTGAAATGCATAGATATTACGCAGAACTCCGATTGCGAAGGCAGCTCACAAAGGTATATCTGACACTGAGGCACGAAAGCGTGGGGAGCAAAC\n",
    "+SRR10153499.1 1 length=250\n",
    "CCCCCCBCCFFFGGGGGGGGGGHGGGGGHHHHHHHGGGHHHHHGHGGGGGGGHHGGHHHHHHHHHHHHHHHHGHHHHHHGHGHGFHHHHHHHHHHHGHHHHHGGGGHHHHHHHHHHGHHHHHHGHHHHHHHHHHHHHGGGGGGGHHGGGGGHHHHHGGGGGGHHHHFHHHHHFHHHHGGGGGGGFGGGGGAEGGGBGGFFFFFFFFBFAFF0BFFFFFFFFFFFFFFFFFFFFFFFEFFFFFFFFB9:BA\n",
    "@SRR10153499.1 1 length=203\n",
    "CCTGTTTGCGCCCCACGCTTTCGTGCCTCAGTGTCAGATATACCTTTGTGAGCTGCCTTCGCAATCGGAGTTCTGCGTAATATCTATGCATTTCACCGCTACACTACGCATTCCGCCCACATCATGTACTCTCAAGTCTTGCAGTTTCAACGGCAAGGCTGAGGTTGAGCCTCAGCTTTTCACCACTGACTTGCAGGACCACC\n",
    "+SRR10153499.1 1 length=203\n",
    ">AAA1B3C@1AAGEGGGGGF0B0BBAFG1FGFGGHHHHHDGBEGFHHHDADAFGFGHFGGFF//EFFCBEFHBGHFFEAEGHFHGBFGF2GHHHEGHGGG>EHFHHFGG?EFHFGCA@CGGHHFGFH2FFHGFFHHGHHHHHHFHHHHFH1ACC@-\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, the files will be in `FASTQ` format. `fasterq-dump` takes shorter times to accomplish the task because of its multi-thread capability. We can assign how many threads we want `fasterq-dump` to use to the task, more threads is less time. Let's check the number of threads available in our compute node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!nproc --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `fasterq-dump` does not take multiple accessions at once, we build a command that uses a `while` loop to proccess all the accessions in the `SRA-accessions.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, notice that our SRA-accessions.txt file has a header \"Accessions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat SRA-accessions.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove the header using the sed command to ignore the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat SRA-accessions.txt | sed -n '1!p'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can add in a while loop to go through each accession in the list, and retrieve the FASTQ files with fasterq-dump in sra-tools.\n",
    "\n",
    "Also note that I can change the number of processors I use with the \"-e\" flag, to make fasterq-dump even faster. I am going to use 12 here.\n",
    "\n",
    "Note that this command takes a couple minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!cat SRA-accessions.txt | sed -n '1!p'| while read line; do apptainer run /contrib/singularity/shared/bhurwitz/sra-tools-3.0.3.sif fasterq-dump $line -e 12; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wasn't that cool! You should see something like this:\n",
    "\n",
    "You should see something like this:\n",
    "\n",
    "spots read      : 14,467\n",
    "reads read      : 28,934\n",
    "reads written   : 28,934\n",
    "spots read      : 13,557\n",
    "reads read      : 27,114\n",
    "reads written   : 27,114\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see this:\n",
    "\n",
    "```\n",
    "total 208M\n",
    "-rw-r--r-- 1 bhurwitz bh_class  227 Sep 14 08:58 SRA-accessions.txt\n",
    "-rw-r--r-- 1 bhurwitz bh_class 7.8M Sep 14 09:24 SRR10153500_1.fastq\n",
    "-rw-r--r-- 1 bhurwitz bh_class 6.7M Sep 14 09:24 SRR10153500_2.fastq\n",
    "-rw-r--r-- 1 bhurwitz bh_class 7.2M Sep 14 09:25 SRR10153501_1.fastq\n",
    "-rw-r--r-- 1 bhurwitz bh_class 6.3M Sep 14 09:25 SRR10153501_2.fastq\n",
    "-rw-r--r-- 1 bhurwitz bh_class 5.5M Sep 14 09:25 SRR10153502_1.fastq\n",
    "-rw-r--r-- 1 bhurwitz bh_class 4.7M Sep 14 09:25 SRR10153502_2.fastq\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls SRR* | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have 36 files (2 for every one of the 18 samples, (with forward and reverse reads) that we will use in the next \n",
    "lessons. \n",
    "\n",
    "`fasterq-dump` is a useful tool to access to public data. Since the explotion of the \n",
    "next-generation sequencing technologies, it is imperative for publicable research projects \n",
    "to upload their data. This is a useful resource for learnes, students and professors to \n",
    "use the already scrutinized data to practice, run newly-develop tools, and teach exercises.\n",
    "\n",
    "\n",
    "Note: To make fasterq-dump even faster, you can user the `prefetch` command and then use `fasterq-dump`. \n",
    "You will see how we do this in the homework for this week. This can be incredibly important when you are downloading large datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
